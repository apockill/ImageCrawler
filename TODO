Alex:
    -

Tyler:
    - When crawler.get_image() is called, it should return the image, and the URL of the page that the image was embedded
      into. This way on alex's end, the image




ERROR:
    - Occured when running 5 browsers, scan depth 3, timeout 60, and running it for about a minute or two

C:\Python34\python.exe "C:/Users/Alex Thiel/Google Drive/Projects/Project - 2017 - Image Crawler Tool/ImageCrawler/main.py"
Exception in thread Thread-5:
Traceback (most recent call last):
  File "C:\Python34\lib\threading.py", line 920, in _bootstrap_inner
    self.run()
  File "C:\Python34\lib\threading.py", line 868, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 66, in crawl_and_return_to_pool
    self._crawl_page(url, browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 136, in _crawl_page
    link_urls = self._get_link_urls(browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 178, in _get_link_urls
    urls.append(link.get_attribute("href"))
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 141, in get_attribute
    resp = self._execute(Command.GET_ELEMENT_ATTRIBUTE, {'name': name})
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 493, in _execute
    return self._parent.execute(command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 250, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 464, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 487, in _request
    self._conn.request(method, parsed_url.path, body, headers)
  File "C:\Python34\lib\http\client.py", line 1088, in request
    self._send_request(method, url, body, headers)
  File "C:\Python34\lib\http\client.py", line 1126, in _send_request
    self.endheaders(body)
  File "C:\Python34\lib\http\client.py", line 1084, in endheaders
    self._send_output(message_body)
  File "C:\Python34\lib\http\client.py", line 922, in _send_output
    self.send(msg)
  File "C:\Python34\lib\http\client.py", line 857, in send
    self.connect()
  File "C:\Python34\lib\http\client.py", line 834, in connect
    self.timeout, self.source_address)
  File "C:\Python34\lib\socket.py", line 512, in create_connection
    raise err
  File "C:\Python34\lib\socket.py", line 503, in create_connection
    sock.connect(sa)
OSError: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted

Exception in thread Thread-4:
Traceback (most recent call last):
  File "C:\Python34\lib\threading.py", line 920, in _bootstrap_inner
    self.run()
  File "C:\Python34\lib\threading.py", line 868, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 66, in crawl_and_return_to_pool
    self._crawl_page(url, browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 136, in _crawl_page
    link_urls = self._get_link_urls(browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 178, in _get_link_urls
    urls.append(link.get_attribute("href"))
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 141, in get_attribute
    resp = self._execute(Command.GET_ELEMENT_ATTRIBUTE, {'name': name})
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 493, in _execute
    return self._parent.execute(command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 250, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 464, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 487, in _request
    self._conn.request(method, parsed_url.path, body, headers)
  File "C:\Python34\lib\http\client.py", line 1088, in request
    self._send_request(method, url, body, headers)
  File "C:\Python34\lib\http\client.py", line 1126, in _send_request
    self.endheaders(body)
  File "C:\Python34\lib\http\client.py", line 1084, in endheaders
    self._send_output(message_body)
  File "C:\Python34\lib\http\client.py", line 922, in _send_output
    self.send(msg)
  File "C:\Python34\lib\http\client.py", line 857, in send
    self.connect()
  File "C:\Python34\lib\http\client.py", line 834, in connect
    self.timeout, self.source_address)
  File "C:\Python34\lib\socket.py", line 512, in create_connection
    raise err
  File "C:\Python34\lib\socket.py", line 503, in create_connection
    sock.connect(sa)
OSError: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted
Exception in thread Thread-2:
Traceback (most recent call last):
  File "C:\Python34\lib\threading.py", line 920, in _bootstrap_inner
    self.run()
  File "C:\Python34\lib\threading.py", line 868, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 66, in crawl_and_return_to_pool
    self._crawl_page(url, browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 135, in _crawl_page
    image_urls = self._get_image_urls(browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 160, in _get_image_urls
    images = browser.find_elements_by_css_selector("img")
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 465, in find_elements_by_css_selector
    return self.find_elements(by=By.CSS_SELECTOR, value=css_selector)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 813, in find_elements
    'value': value})['value']
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 250, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 464, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 487, in _request
    self._conn.request(method, parsed_url.path, body, headers)
  File "C:\Python34\lib\http\client.py", line 1088, in request
    self._send_request(method, url, body, headers)
  File "C:\Python34\lib\http\client.py", line 1126, in _send_request
    self.endheaders(body)
  File "C:\Python34\lib\http\client.py", line 1084, in endheaders
    self._send_output(message_body)
  File "C:\Python34\lib\http\client.py", line 922, in _send_output
    self.send(msg)
  File "C:\Python34\lib\http\client.py", line 857, in send
    self.connect()
  File "C:\Python34\lib\http\client.py", line 834, in connect
    self.timeout, self.source_address)
  File "C:\Python34\lib\socket.py", line 512, in create_connection
    raise err
  File "C:\Python34\lib\socket.py", line 503, in create_connection
    sock.connect(sa)
OSError: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted


Exception in thread Thread-3:
Traceback (most recent call last):
  File "C:\Python34\lib\threading.py", line 920, in _bootstrap_inner
    self.run()
  File "C:\Python34\lib\threading.py", line 868, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 66, in crawl_and_return_to_pool
    self._crawl_page(url, browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 136, in _crawl_page
    link_urls = self._get_link_urls(browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 178, in _get_link_urls
    urls.append(link.get_attribute("href"))
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 141, in get_attribute
    resp = self._execute(Command.GET_ELEMENT_ATTRIBUTE, {'name': name})
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 493, in _execute
    return self._parent.execute(command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 250, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 464, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 487, in _request
    self._conn.request(method, parsed_url.path, body, headers)
  File "C:\Python34\lib\http\client.py", line 1088, in request
    self._send_request(method, url, body, headers)
  File "C:\Python34\lib\http\client.py", line 1126, in _send_request
    self.endheaders(body)
  File "C:\Python34\lib\http\client.py", line 1084, in endheaders
    self._send_output(message_body)
  File "C:\Python34\lib\http\client.py", line 922, in _send_output
    self.send(msg)
  File "C:\Python34\lib\http\client.py", line 857, in send
    self.connect()
  File "C:\Python34\lib\http\client.py", line 834, in connect
    self.timeout, self.source_address)
  File "C:\Python34\lib\socket.py", line 512, in create_connection
    raise err
  File "C:\Python34\lib\socket.py", line 503, in create_connection
    sock.connect(sa)
OSError: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted

Exception in thread Thread-6:
Traceback (most recent call last):
  File "C:\Python34\lib\threading.py", line 920, in _bootstrap_inner
    self.run()
  File "C:\Python34\lib\threading.py", line 868, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 66, in crawl_and_return_to_pool
    self._crawl_page(url, browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 150, in _crawl_page
    self._crawl_page(link_url, browser, depth=depth+1)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 136, in _crawl_page
    link_urls = self._get_link_urls(browser)
  File "C:\Users\Alex Thiel\Google Drive\Projects\Project - 2017 - Image Crawler Tool\ImageCrawler\crawler.py", line 178, in _get_link_urls
    urls.append(link.get_attribute("href"))
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 141, in get_attribute
    resp = self._execute(Command.GET_ELEMENT_ATTRIBUTE, {'name': name})
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webelement.py", line 493, in _execute
    return self._parent.execute(command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 250, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 464, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Python34\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 487, in _request
    self._conn.request(method, parsed_url.path, body, headers)
  File "C:\Python34\lib\http\client.py", line 1088, in request
    self._send_request(method, url, body, headers)
  File "C:\Python34\lib\http\client.py", line 1126, in _send_request
    self.endheaders(body)
  File "C:\Python34\lib\http\client.py", line 1084, in endheaders
    self._send_output(message_body)
  File "C:\Python34\lib\http\client.py", line 922, in _send_output
    self.send(msg)
  File "C:\Python34\lib\http\client.py", line 857, in send
    self.connect()
  File "C:\Python34\lib\http\client.py", line 834, in connect
    self.timeout, self.source_address)
  File "C:\Python34\lib\socket.py", line 512, in create_connection
    raise err
  File "C:\Python34\lib\socket.py", line 503, in create_connection
    sock.connect(sa)
OSError: [WinError 10048] Only one usage of each socket address (protocol/network address/port) is normally permitted

